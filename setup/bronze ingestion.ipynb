{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3f8e1a5-7cc7-4de5-b409-ddae784d10d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit, current_timestamp\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7505849b-8a60-4c68-8bbb-222fbad6f4d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"token\", \"\", \"token\")\n",
    "token = dbutils.widgets.get(\"token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d049d38-4716-4be6-b8a2-9131d8695c2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Spark session\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b704124e-9c91-4d5f-9ee8-825eac39c15c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# URL do CSV\n",
    "url_raw = \"https://raw.githubusercontent.com/RafaelaSantos92/projeto-final/2d91c9a99aae72fa73f779d77e2f49fbf6a85c5d/raw-data/Populacao%20-%20Censo%202022.csv\"\n",
    "\n",
    "# Token\n",
    "headers = {'Authorization': f'token {token}'} if token else None\n",
    "\n",
    "# request\n",
    "response = requests.get(url_raw, headers=headers)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Carrega CSV em pandas\n",
    "pdf = pd.read_csv(BytesIO(response.content))\n",
    "\n",
    "# Normaliza os nomes das colunas para Delta\n",
    "pdf.columns = [\n",
    "    c.strip()\n",
    "     .lower()\n",
    "     .replace(\" \", \"_\")\n",
    "     .replace(\"-\", \"_\")\n",
    "     .replace(\",\", \"\")\n",
    "     .replace(\"(\", \"\")\n",
    "     .replace(\")\", \"\")\n",
    "     .replace(\".\", \"\")\n",
    "     .encode('ascii', errors='ignore').decode()\n",
    "    for c in pdf.columns\n",
    "]\n",
    "\n",
    "# Converte para Spark DataFrame\n",
    "df = spark.createDataFrame(pdf)\n",
    "\n",
    "# Adiciona colunas da camada Bronze\n",
    "df = df.withColumn(\"source_file\", lit(url_raw)) \\\n",
    "       .withColumn(\"ingestion_time\", current_timestamp())\n",
    "\n",
    "# Mostra 5 linhas para conferir\n",
    "df.show(5)\n",
    "\n",
    "# Salva como tabela gerenciada no schema Bronze\n",
    "df.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"projeto_final_bronze.bronze_ibge_censo_2022\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdaeabf5-b980-4fe4-b61f-0aa19cb0a48b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit, current_timestamp\n",
    "import re\n",
    "\n",
    "url = \"https://api.github.com/repos/RafaelaSantos92/projeto-final/contents/raw-data/panorama-da-eja-no-brasil.xlsx?ref=main\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"token {token}\",\n",
    "    \"Accept\": \"application/vnd.github.v3.raw\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "response.raise_for_status()\n",
    "\n",
    "df = pd.read_excel(BytesIO(response.content))\n",
    "\n",
    "# Remove colunas vazias e colunas \"Unnamed\"\n",
    "df = df.dropna(axis=1, how=\"all\")\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed', case=False)]\n",
    "\n",
    "# NORMALIZAÇÃO SEGURA PARA DELTA\n",
    "def normalize_column_name(col):\n",
    "    # Remove acentos e caracteres não ASCII\n",
    "    col = col.encode('ascii', errors='ignore').decode()\n",
    "    # Substitui qualquer caractere que não seja letra, número ou underline por underline\n",
    "    col = re.sub(r'[^0-9a-zA-Z_]', '_', col)\n",
    "    # Remove múltiplos underlines seguidos\n",
    "    col = re.sub(r'_+', '_', col)\n",
    "    # Remove underline no começo ou no final\n",
    "    col = col.strip('_')\n",
    "    # Força lowercase\n",
    "    return col.lower()\n",
    "\n",
    "df.columns = [normalize_column_name(c) for c in df.columns]\n",
    "\n",
    "# Converte todas as colunas para string\n",
    "df = df.astype(str)\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df_spark = spark.createDataFrame(df)\n",
    "\n",
    "df_spark = df_spark.withColumn(\"source_file\", lit(\"panorama-da-eja-no-brasil.xlsx\")) \\\n",
    "                   .withColumn(\"ingestion_time\", current_timestamp())\n",
    "\n",
    "# Mostra algumas linhas\n",
    "df_spark.show(5)\n",
    "\n",
    "# Salva como tabela Delta no schema Bronze\n",
    "df_spark.write.format(\"delta\") \\\n",
    "       .mode(\"overwrite\") \\\n",
    "       .saveAsTable(\"projeto_final_bronze.bronze_panorama_eja\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7480593842891727,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze ingestion",
   "widgets": {
    "token": {
     "currentValue": "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",
     "nuid": "91a63d33-a400-45be-b4e5-2446f29f5a71",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "token",
      "name": "token",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "token",
      "name": "token",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
